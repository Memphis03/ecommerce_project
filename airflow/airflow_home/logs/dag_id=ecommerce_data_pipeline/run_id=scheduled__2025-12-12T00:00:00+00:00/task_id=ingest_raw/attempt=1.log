{"timestamp":"2025-12-12T17:45:13.454319","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-12-12T17:45:13.455204","level":"info","event":"Filling up the DagBag from /home/mountah_lodia/ecommerce_project/ecommerce_project/airflow/dags/ecommerce_pipeline_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-12-12T17:45:13.544259Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T17:45:13.544376Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T17:45:13.544487Z","level":"info","event":"Current task name:ingest_raw","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T17:45:13.544562Z","level":"info","event":"Dag name:ecommerce_data_pipeline","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T17:45:13.545417","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:13.546276","level":"info","event":"Running command: ['/usr/bin/bash', '-c', 'python3 /home/mountah_lodia/ecommerce_project/ecommerce_project/airflow/scripts/ingest_raw.py /home/mountah_lodia/ecommerce_project/ecommerce_project/data/raw/data.csv /home/mountah_lodia/ecommerce_project/ecommerce_project/data']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:13.556115","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:15.053459","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:17.230622","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:17.255849","level":"info","event":"25/12/12 17:45:17 WARN Utils: Your hostname, MuntahLodia, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:17.263007","level":"info","event":"25/12/12 17:45:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:17.969951","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:17.970585","level":"info","event":"Setting default log level to \"WARN\".","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:17.970896","level":"info","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:18.956051","level":"info","event":"25/12/12 17:45:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:41.936814","level":"info","event":"\r[Stage 0:>                                                          (0 + 0) / 1]\r\r[Stage 0:>                                                          (0 + 1) / 1]\r\r                                                                                \r\r[Stage 1:>                                                          (0 + 8) / 8]\r\r[Stage 1:=======>                                                   (1 + 7) / 8]\r\r[Stage 1:======================>                                    (3 + 5) / 8]\r\r[Stage 1:=============================>                             (4 + 4) / 8]\r\r                                                                                \r\r[Stage 2:>                                                          (0 + 8) / 8]\r25/12/12 17:45:41 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:41.937128","level":"info","event":"Scaling row group sizes to 95.00% for 8 writers","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:45.725311","level":"info","event":"\r[Stage 2:======================>                                    (3 + 5) / 8]\r\r                                                                                \r[INFO] Bronze généré : /home/mountah_lodia/ecommerce_project/ecommerce_project/data/bronze/raw_data.parquet","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:46.204544","level":"info","event":"Command exited with return code 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:46.205311","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019b13aa-aff0-721b-aae0-2806b9996645'), task_id='ingest_raw', dag_id='ecommerce_data_pipeline', run_id='scheduled__2025-12-12T00:00:00+00:00', try_number=1, map_index=-1, hostname='MuntahLodia.localdomain', context_carrier=None, task=<Task(BashOperator): ingest_raw>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=1, start_date=datetime.datetime(2025, 12, 12, 17, 45, 12, 382636, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None, log_url='http://localhost:8080/dags/ecommerce_data_pipeline/runs/scheduled__2025-12-12T00%3A00%3A00%2B00%3A00/tasks/ingest_raw?try_number=1')","logger":"task"}
{"timestamp":"2025-12-12T17:45:46.253254Z","level":"info","event":"✅ Succès : ingest_raw","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T17:45:46.253402Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T17:45:46.253449Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T17:45:46.253741Z","level":"info","event":"Task operator:<Task(BashOperator): ingest_raw>","chan":"stdout","logger":"task"}
