{"timestamp":"2025-12-12T17:45:46.331032","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-12-12T17:45:46.331996","level":"info","event":"Filling up the DagBag from /home/mountah_lodia/ecommerce_project/ecommerce_project/airflow/dags/ecommerce_pipeline_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-12-12T17:45:46.369908Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T17:45:46.370010Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T17:45:46.370101Z","level":"info","event":"Current task name:ingest_raw","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T17:45:46.370146Z","level":"info","event":"Dag name:ecommerce_data_pipeline","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T17:45:46.370682","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:46.371396","level":"info","event":"Running command: ['/usr/bin/bash', '-c', 'python3 /home/mountah_lodia/ecommerce_project/ecommerce_project/airflow/scripts/ingest_raw.py /home/mountah_lodia/ecommerce_project/ecommerce_project/data/raw/data.csv /home/mountah_lodia/ecommerce_project/ecommerce_project/data']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:46.381153","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:47.148233","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:48.746147","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:48.771360","level":"info","event":"25/12/12 17:45:48 WARN Utils: Your hostname, MuntahLodia, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:48.778565","level":"info","event":"25/12/12 17:45:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:49.647505","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:49.648420","level":"info","event":"Setting default log level to \"WARN\".","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:49.648701","level":"info","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:45:50.330722","level":"info","event":"25/12/12 17:45:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:46:08.472676","level":"info","event":"\r[Stage 0:>                                                          (0 + 1) / 1]\r\r                                                                                \r\r[Stage 1:>                                                          (0 + 8) / 8]\r\r[Stage 1:=======>                                                   (1 + 7) / 8]\r\r[Stage 1:==============>                                            (2 + 6) / 8]\r\r[Stage 1:=============================>                             (4 + 4) / 8]\r\r[Stage 1:===================================================>       (7 + 1) / 8]\r\r                                                                                \r\r[Stage 2:>                                                          (0 + 8) / 8]\r25/12/12 17:46:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:46:08.473117","level":"info","event":"Scaling row group sizes to 95.00% for 8 writers","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:46:13.909716","level":"info","event":"\r[Stage 2:======================>                                    (3 + 5) / 8]\r\r[Stage 2:===================================================>       (7 + 1) / 8]\r\r                                                                                \r[INFO] Bronze généré : /home/mountah_lodia/ecommerce_project/ecommerce_project/data/bronze/raw_data.parquet","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:46:14.609424","level":"info","event":"Command exited with return code 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T17:46:14.611571","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019b13aa-ccc4-7952-b621-b7d98cbfc0df'), task_id='ingest_raw', dag_id='ecommerce_data_pipeline', run_id='manual__2025-12-12T17:45:19.238918+00:00', try_number=1, map_index=-1, hostname='MuntahLodia.localdomain', context_carrier=None, task=<Task(BashOperator): ingest_raw>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=1, start_date=datetime.datetime(2025, 12, 12, 17, 45, 46, 294565, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None, log_url='http://localhost:8080/dags/ecommerce_data_pipeline/runs/manual__2025-12-12T17%3A45%3A19.238918%2B00%3A00/tasks/ingest_raw?try_number=1')","logger":"task"}
{"timestamp":"2025-12-12T17:46:14.678998Z","level":"info","event":"✅ Succès : ingest_raw","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T17:46:14.679297Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T17:46:14.679419Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T17:46:14.680616Z","level":"info","event":"Task operator:<Task(BashOperator): ingest_raw>","chan":"stdout","logger":"task"}
