{"timestamp":"2025-12-12T21:19:52.666269","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-12-12T21:19:52.667026","level":"info","event":"Filling up the DagBag from /home/mountah_lodia/ecommerce_project/ecommerce_project/airflow/dags/ecommerce_pipeline_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-12-12T21:19:52.776933Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T21:19:52.777136Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T21:19:52.777427Z","level":"info","event":"Current task name:ingest_raw","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T21:19:52.777526Z","level":"info","event":"Dag name:ecommerce_data_pipeline","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T21:19:52.778496","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T21:19:52.779656","level":"info","event":"Running command: ['/usr/bin/bash', '-c', 'python3 /home/mountah_lodia/ecommerce_project/ecommerce_project/airflow/scripts/ingest_raw.py /home/mountah_lodia/ecommerce_project/ecommerce_project/data/raw/data.csv /home/mountah_lodia/ecommerce_project/ecommerce_project/data 2011-05-17']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T21:19:52.792512","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T21:19:53.966154","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T21:19:56.552609","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T21:19:56.574297","level":"info","event":"25/12/12 21:19:56 WARN Utils: Your hostname, MuntahLodia, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T21:19:56.580894","level":"info","event":"25/12/12 21:19:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T21:19:57.219342","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T21:19:57.220158","level":"info","event":"Setting default log level to \"WARN\".","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T21:19:57.220449","level":"info","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T21:19:58.098147","level":"info","event":"25/12/12 21:19:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T21:20:20.223303","level":"info","event":"\r[Stage 0:>                                                          (0 + 1) / 1]\r\r                                                                                \r\r[Stage 1:>                                                          (0 + 8) / 8]\r\r[Stage 1:=======>                                                   (1 + 7) / 8]\r\r[Stage 1:==============>                                            (2 + 6) / 8]\r\r                                                                                \r\r[Stage 2:>                                                          (0 + 8) / 8]\r\r[Stage 2:=======>                                                   (1 + 7) / 8]\r\r[Stage 2:=============================>                             (4 + 4) / 8]\r\r[Stage 2:====================================>                      (5 + 3) / 8]\r\r[Stage 2:===========================================================(8 + 0) / 8]\r\r                                                                                \r[INFO] Bronze généré : /home/mountah_lodia/ecommerce_project/ecommerce_project/data/bronze/bronze_20110517.parquet","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T21:20:20.879871","level":"info","event":"Command exited with return code 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-12-12T21:20:20.881378","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019b146f-3206-7099-80c5-0837e88f1c66'), task_id='ingest_raw', dag_id='ecommerce_data_pipeline', run_id='manual__2025-12-12T21:19:50.257629+00:00', try_number=1, map_index=-1, hostname='MuntahLodia.localdomain', context_carrier=None, task=<Task(BashOperator): ingest_raw>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=1, start_date=datetime.datetime(2025, 12, 12, 21, 19, 51, 258795, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None, log_url='http://localhost:8080/dags/ecommerce_data_pipeline/runs/manual__2025-12-12T21%3A19%3A50.257629%2B00%3A00/tasks/ingest_raw?try_number=1')","logger":"task"}
{"timestamp":"2025-12-12T21:20:21.019776Z","level":"info","event":"✅ Succès : ingest_raw","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T21:20:21.020250Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T21:20:21.020425Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","chan":"stdout","logger":"task"}
{"timestamp":"2025-12-12T21:20:21.026900Z","level":"info","event":"Task operator:<Task(BashOperator): ingest_raw>","chan":"stdout","logger":"task"}
